# Navigation for visually impaired people

this repo is an implementation of semantic segmentation using cityscape dataset to help visually impaired people to guide them to some specified object like (car, sidewalk, bus ... ect) and directed by a clear voice in real-time like turn left now and walk forward

## requirements:

-   An NVIDIA GPU and CUDA 9.0 or higher. Some operations only have gpu implementation.
-   PyTorch (>= 0.5.1)
-   Python 3
-   numpy
-   sklearn
-   h5py
-   scikit-image
-   pillow
-   piexif
-   cffi
-   tqdm
-   dominate
-   tensorboardX
-   opencv-python
-   nose
-   ninja
- [pretrained model ](https://drive.google.com/file/d/1P4kPaMY-SmQ3yPJQTJ7xMGAB_Su-1zTl/view)

## How it works!

![16](https://user-images.githubusercontent.com/49832164/138503895-e67869b9-442e-45ef-a40a-cd51606007a5.png)
![17](https://user-images.githubusercontent.com/49832164/138503938-c43c2ef9-9111-4d5c-81df-e40b674b5a2a.png)
![19](https://user-images.githubusercontent.com/49832164/138503989-09903e9a-e557-4b6a-842d-97d01bdf2e63.png)

## Recources
[ganlumomo/semantic-segmentation](https://github.com/ganlumomo/semantic-segmentation)
